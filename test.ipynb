{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (4.46.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2024.7.24)\n",
      "Requirement already satisfied: requests in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\moham\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Original Dataset:\n",
      "                Username                                     Title  \\\n",
      "0            John McLean                            Utter Rubbish.   \n",
      "1  Angry from Manchester       5/5 for the car. 0/5 for the dealer   \n",
      "2                Kevin O   Musk is the most embarrassing man that…   \n",
      "3         Andrew Haworth    Put a deposit on a cybertruck 4 years…   \n",
      "4             Ahmed Radm  Thanks for the office tomorrow so I can…   \n",
      "\n",
      "                                             Content  Rating  \\\n",
      "0  Utter Rubbish.3 owner for the last 3 years. Go...       1   \n",
      "1  The car (model 3) is excellent, though feels a...       3   \n",
      "2  Musk is the most embarrassing man that has eve...       1   \n",
      "3  Put a deposit on a cybertruck 4 years ago. For...       1   \n",
      "4  Thanks for the office tomorrow so I can do it ...       5   \n",
      "\n",
      "                       Date  \n",
      "0  2024-11-19T06:55:16.000Z  \n",
      "1  2024-11-18T14:58:54.000Z  \n",
      "2  2024-11-21T09:13:18.000Z  \n",
      "3  2024-11-20T18:43:26.000Z  \n",
      "4  2024-11-23T01:27:42.000Z  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\program files\\python311\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Dataset with Sentiments:\n",
      "                Username                                     Title  \\\n",
      "0            John McLean                            Utter Rubbish.   \n",
      "1  Angry from Manchester       5/5 for the car. 0/5 for the dealer   \n",
      "2                Kevin O   Musk is the most embarrassing man that…   \n",
      "3         Andrew Haworth    Put a deposit on a cybertruck 4 years…   \n",
      "4             Ahmed Radm  Thanks for the office tomorrow so I can…   \n",
      "\n",
      "                                             Content  Rating  \\\n",
      "0  Utter Rubbish.3 owner for the last 3 years. Go...       1   \n",
      "1  The car (model 3) is excellent, though feels a...       3   \n",
      "2  Musk is the most embarrassing man that has eve...       1   \n",
      "3  Put a deposit on a cybertruck 4 years ago. For...       1   \n",
      "4  Thanks for the office tomorrow so I can do it ...       5   \n",
      "\n",
      "                       Date Sentiment  \n",
      "0  2024-11-19T06:55:16.000Z  negative  \n",
      "1  2024-11-18T14:58:54.000Z  negative  \n",
      "2  2024-11-21T09:13:18.000Z  negative  \n",
      "3  2024-11-20T18:43:26.000Z  negative  \n",
      "4  2024-11-23T01:27:42.000Z  positive  \n"
     ]
    }
   ],
   "source": [
    "!pip install transformers pandas\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "file_path = 'Tesla_Trustpilot_Reviews.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Original Dataset:\")\n",
    "print(data.head())\n",
    "\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=\"lxyuan/distilbert-base-multilingual-cased-sentiments-student\")\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return None  # Skip invalid entries\n",
    "    # Truncate the text if it exceeds the model's maximum input size\n",
    "    truncated_text = text[:512]  # Adjust as per model's max token limit\n",
    "    result = sentiment_model(truncated_text)\n",
    "    return result[0]['label']\n",
    "\n",
    "\n",
    "data['Sentiment'] = data['Content'].apply(analyze_sentiment)\n",
    "\n",
    "output_file = 'Tesla_Trustpilot_Reviews_with_Sentiment.csv'\n",
    "data.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Updated Dataset with Sentiments:\")\n",
    "print(data.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
