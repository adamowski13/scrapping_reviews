{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 15:55:01,500 - utils.scrape_data - INFO - Scraping page 1...\n",
      "2024-11-26 15:55:03,878 - utils.scrape_data - INFO - Scraping page 2...\n",
      "2024-11-26 15:55:06,043 - utils.scrape_data - INFO - Scraping page 3...\n",
      "2024-11-26 15:55:08,141 - utils.scrape_data - INFO - Scraping page 4...\n",
      "2024-11-26 15:55:10,271 - utils.scrape_data - INFO - Scraping page 5...\n",
      "2024-11-26 15:55:12,384 - utils.scrape_data - INFO - Scraping page 6...\n",
      "2024-11-26 15:55:14,481 - utils.scrape_data - INFO - Scraping page 7...\n",
      "2024-11-26 15:55:16,596 - utils.scrape_data - INFO - Scraping page 8...\n",
      "2024-11-26 15:55:18,704 - utils.scrape_data - INFO - Scraping page 9...\n",
      "2024-11-26 15:55:20,816 - utils.scrape_data - INFO - Scraping page 10...\n",
      "2024-11-26 15:55:22,945 - utils.scrape_data - INFO - Scraping page 11...\n",
      "2024-11-26 15:55:25,074 - utils.scrape_data - INFO - Scraping page 12...\n",
      "2024-11-26 15:55:27,235 - utils.scrape_data - INFO - Scraping page 13...\n",
      "2024-11-26 15:55:29,346 - utils.scrape_data - INFO - Scraping page 14...\n",
      "2024-11-26 15:55:31,466 - utils.scrape_data - INFO - Scraping page 15...\n",
      "2024-11-26 15:55:33,584 - utils.scrape_data - INFO - Scraping page 16...\n",
      "2024-11-26 15:55:35,882 - utils.scrape_data - INFO - Scraping page 17...\n",
      "2024-11-26 15:55:38,226 - utils.scrape_data - INFO - Scraping page 18...\n",
      "2024-11-26 15:55:40,354 - utils.scrape_data - INFO - Scraping page 19...\n",
      "2024-11-26 15:55:42,454 - utils.scrape_data - INFO - Scraping page 20...\n",
      "2024-11-26 15:55:44,588 - utils.scrape_data - INFO - Scraping page 21...\n",
      "2024-11-26 15:55:46,703 - utils.scrape_data - INFO - Scraping page 22...\n",
      "2024-11-26 15:55:48,814 - utils.scrape_data - INFO - Scraping page 23...\n",
      "2024-11-26 15:55:50,987 - utils.scrape_data - INFO - Scraping page 24...\n",
      "2024-11-26 15:55:53,122 - utils.scrape_data - INFO - Scraping page 25...\n",
      "2024-11-26 15:55:55,259 - utils.scrape_data - INFO - Scraping page 26...\n",
      "2024-11-26 15:55:57,369 - utils.scrape_data - INFO - Scraping page 27...\n",
      "2024-11-26 15:55:59,784 - utils.scrape_data - INFO - Scraping page 28...\n",
      "2024-11-26 15:56:02,251 - utils.scrape_data - INFO - Scraping page 29...\n",
      "2024-11-26 15:56:04,374 - utils.scrape_data - INFO - Scraping page 30...\n",
      "2024-11-26 15:56:06,512 - utils.scrape_data - INFO - Scraping page 31...\n",
      "2024-11-26 15:56:09,082 - utils.scrape_data - INFO - Scraping page 32...\n",
      "2024-11-26 15:56:11,277 - utils.scrape_data - INFO - Scraping page 33...\n",
      "2024-11-26 15:56:13,377 - utils.scrape_data - INFO - Scraping page 34...\n",
      "2024-11-26 15:56:15,699 - utils.scrape_data - INFO - Scraping page 35...\n",
      "2024-11-26 15:56:17,808 - utils.scrape_data - INFO - Scraping page 36...\n",
      "2024-11-26 15:56:19,922 - utils.scrape_data - INFO - Scraping page 37...\n",
      "2024-11-26 15:56:22,038 - utils.scrape_data - INFO - Scraping page 38...\n",
      "2024-11-26 15:56:24,156 - utils.scrape_data - INFO - Scraping page 39...\n",
      "2024-11-26 15:56:26,311 - utils.scrape_data - INFO - Scraping page 40...\n",
      "2024-11-26 15:56:28,423 - utils.scrape_data - INFO - Scraping page 41...\n",
      "2024-11-26 15:56:30,557 - utils.scrape_data - INFO - Scraping page 42...\n",
      "2024-11-26 15:56:32,684 - utils.scrape_data - INFO - Scraping page 43...\n",
      "2024-11-26 15:56:35,045 - utils.scrape_data - INFO - Scraping page 44...\n",
      "2024-11-26 15:56:37,190 - utils.scrape_data - INFO - Scraping page 45...\n",
      "2024-11-26 15:56:39,331 - utils.scrape_data - INFO - Scraping page 46...\n",
      "2024-11-26 15:56:41,463 - utils.scrape_data - INFO - Scraping page 47...\n",
      "2024-11-26 15:56:43,584 - utils.scrape_data - INFO - Scraping page 48...\n",
      "2024-11-26 15:56:45,721 - utils.scrape_data - INFO - Scraping page 49...\n",
      "2024-11-26 15:56:47,909 - utils.scrape_data - INFO - Scraping page 50...\n",
      "2024-11-26 15:56:50,061 - utils.scrape_data - INFO - Scraping terminé. 1000 avis extraits.\n",
      "2024-11-26 15:56:50,073 - utils.clean_data - INFO - Début du nettoyage des données\n",
      "2024-11-26 15:56:50,162 - utils.clean_data - INFO - Nettoyage des données terminé avec succès\n",
      "2024-11-26 15:56:50,174 - utils.extract_sentiment - INFO - Début de l'extraction des mots-clés\n",
      "2024-11-26 15:56:50,224 - utils.extract_sentiment - INFO - Extraction des mots-clés terminée avec succès\n",
      "2024-11-26 15:56:50,245 - utils.extract_sentiment - INFO - Début de l'analyse des sentiments sur le DataFrame\n",
      "2024-11-26 15:56:56,449 - utils.extract_sentiment - INFO - Analyse des sentiments terminée avec succès\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.clean_data import clean_and_structure_data\n",
    "from utils.extract_sentiment import extract_keywords, analyse_all_sentiments\n",
    "from utils.scrape_data import scrape_trustpilot_reviews\n",
    "\n",
    "\n",
    "num_pages = 50\n",
    "\n",
    "scrape_data = scrape_trustpilot_reviews(num_pages=num_pages)\n",
    "output_path = '.\\\\data\\\\scrape_data.csv'\n",
    "scrape_data.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "clean_data = clean_and_structure_data(file_path=output_path)\n",
    "output_path = '.\\\\data\\\\clean_data.csv'\n",
    "clean_data.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "keywords_data = extract_keywords(df=clean_data)\n",
    "output_path = '.\\\\data\\\\keywords_data.csv'\n",
    "keywords_data.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "sentiments_analyze = analyse_all_sentiments(data_frame=clean_data)\n",
    "output_path = '.\\\\data\\\\sentiments_analyze.csv'\n",
    "sentiments_analyze.to_csv(output_path, index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
